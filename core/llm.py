from openai import OpenAI
from config import config

class LLMService:
    def __init__(self):
        self.client = OpenAI(
            api_key=config.OPENAI_API_KEY,
            base_url=config.OPENAI_BASE_URL
        )
        self.model = config.LLM_MODEL

    def generate_personal_summary(self, user_name, chat_history):
        """
        Generate a summary relevant to a specific user.
        """
        if not chat_history:
            return "æš‚æ— æœ€è¿‘çš„èŠå¤©è®°å½•ï¼Œæ— æ³•ç”Ÿæˆæ‘˜è¦ã€‚"

        prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¾¤èŠåŠ©æ‰‹ã€‚å½“å‰è¯·æ±‚ç”¨æˆ·æ˜¯ï¼šã€{user_name}ã€‘ã€‚
        è¯·é˜…è¯»ä»¥ä¸‹ç¾¤èŠè®°å½•ï¼ˆæ ¼å¼ï¼š[æ—¶é—´] å‘é€è€…: å†…å®¹ï¼‰ï¼Œå¹¶æå–**ä»…ä¸è¯¥ç”¨æˆ·é«˜åº¦ç›¸å…³**çš„ä¿¡æ¯ã€‚
        
        èŠå¤©è®°å½•ï¼š
        {chat_history}
        
        è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡º Markdownï¼ˆæ— ç›¸å…³å†…å®¹åˆ™è·³è¿‡å¯¹åº”æ ‡é¢˜ï¼‰ï¼š
        
        ### ğŸ”´ å¾…ä½ å¤„ç† (Action Items)
        - [ ] ä»»åŠ¡æè¿° (æ¥æºï¼šå‘é€è€…å)
        
        ### ğŸŸ¡ æåˆ°ä½ çš„ (Mentions)
        - æ‘˜è¦å†…å®¹
        
        ### ğŸŸ¢ ä½ çš„æœªå†³é—®é¢˜
        - é—®é¢˜æè¿°
        """
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print(f"LLM Error: {e}")
            return "æŠ±æ­‰ï¼ŒAI æ€»ç»“æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚"
